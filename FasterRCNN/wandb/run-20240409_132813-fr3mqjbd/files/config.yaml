wandb_version: 1

max_lr:
  desc: null
  value: 0.01
weight_decay:
  desc: null
  value: 0.0001
momentum:
  desc: null
  value: 0.9
max_epochs:
  desc: null
  value: 100
batch_size:
  desc: null
  value: 128
in_channels:
  desc: null
  value: 3
num_classes:
  desc: null
  value: 100
use_pretrained_weights:
  desc: null
  value: true
test_model:
  desc: null
  value: false
checkpoint_path:
  desc: null
  value: null
early_stopping_patience:
  desc: null
  value: 10
num_workers:
  desc: null
  value: 16
check_val_every_n_epoch:
  desc: null
  value: 3
devices:
  desc: null
  value: auto
enable_progress_bar:
  desc: null
  value: false
wandb_project:
  desc: null
  value: CIFAR100
wandb_experiment_name:
  desc: null
  value: resnet_50_idun
train_split_ratio:
  desc: null
  value: 0.8
data_root:
  desc: null
  value: ./data
checkpoint_folder:
  desc: null
  value: ./checkpoints/
_wandb:
  desc: null
  value:
    python_version: 3.10.12
    cli_version: 0.16.6
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1712662093.0
    t:
      1:
      - 1
      - 41
      - 55
      2:
      - 1
      - 41
      - 55
      3:
      - 7
      - 13
      - 16
      - 23
      4: 3.10.12
      5: 0.16.6
      8:
      - 5
      13: linux-x86_64
    m:
    - 1: trainer/global_step
      6:
      - 3
    - 1: lr-SGD
      5: 1
      6:
      - 1
    - 1: train/loss
      5: 1
      6:
      - 1
    - 1: train/acc
      5: 1
      6:
      - 1
    - 1: epoch
      5: 1
      6:
      - 1
    - 1: val/loss
      5: 1
      6:
      - 1
    - 1: val/acc
      5: 1
      6:
      - 1
    - 1: test/acc
      5: 1
      6:
      - 1
